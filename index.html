<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Teachable Machine Audio + MQTT</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            padding: 20px;
        }
        #label-container div {
            margin-bottom: 6px;
            font-size: 18px;
        }
        button {
            padding: 10px 20px;
            margin-top: 10px;
            font-size: 16px;
            cursor: pointer;
        }
    </style>
</head>

<body>

    <h2>Teachable Machine Audio Model</h2>
    <button onclick="init()">Start Listening</button>
    <div id="label-container"></div>

    <!-- Teachable Machine Libraries -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js"></script>

    <!-- MQTT Browser Client -->
    <script src="https://unpkg.com/mqtt/dist/mqtt.min.js"></script>

    <script type="text/javascript">

        /* -----------------------------------------
            MQTT CONNECTION
        ----------------------------------------- */

        const options = {
            clean: true,
            connectTimeout: 4000
        };

        const client = mqtt.connect("wss://broker.hivemq.com:8884/mqtt", options);

        client.on("connect", () => {
            console.log("MQTT Connected");
        });

        /* -----------------------------------------
            TEACHABLE MACHINE
        ----------------------------------------- */

        const URL = "./my_model/";

        async function createModel() {
            const checkpointURL = URL + "model.json";
            const metadataURL = URL + "metadata.json";

            const recognizer = speechCommands.create(
                "BROWSER_FFT",
                undefined,
                checkpointURL,
                metadataURL
            );

            await recognizer.ensureModelLoaded();
            return recognizer;
        }

        async function init() {
            const recognizer = await createModel();
            const classLabels = recognizer.wordLabels();
            const labelContainer = document.getElementById("label-container");

            // Create UI rows for each class
            for (let i = 0; i < classLabels.length; i++) {
                labelContainer.appendChild(document.createElement("div"));
            }

            recognizer.listen(result => {
                const scores = result.scores;

                // Update screen
                for (let i = 0; i < classLabels.length; i++) {
                    labelContainer.childNodes[i].innerHTML =
                        classLabels[i] + ": " + scores[i].toFixed(2);
                }

                // Top result
                let maxIndex = 0;
                for (let i = 1; i < scores.length; i++) {
                    if (scores[i] > scores[maxIndex]) {
                        maxIndex = i;
                    }
                }

                const topLabel = classLabels[maxIndex];
                const topValue = scores[maxIndex];

                // If confident, publish
                if (topValue >= 0.75) {
                    console.log("Publishing:", topLabel);
                    client.publish("tm/audio", topLabel);
                }

            }, {
                includeSpectrogram: true,
                probabilityThreshold: 0.75,
                invokeCallbackOnNoiseAndUnknown: true,
                overlapFactor: 0.50
            });
        }

    </script>

</body>
</html>
